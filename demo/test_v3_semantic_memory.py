"""æµ‹è¯• V3 API è¯­ä¹‰è®°å¿†æ£€ç´¢åŠŸèƒ½

éªŒè¯è¯­ä¹‰è®°å¿†æ£€ç´¢æ˜¯å¦æ­£ç¡®å°è£…åˆ° V3 API ä¸­
"""

import asyncio

from core.di import get_bean_by_type
from infra_layer.adapters.input.api.v3.agentic_v3_controller import (
    AgenticV3Controller,
)
from infra_layer.adapters.out.persistence.repository.conversation_meta_raw_repository import (
    ConversationMetaRawRepository,
)


class MockRequest:
    def __init__(self, data):
        self.data = data
    
    async def json(self):
        return self.data


async def test_semantic_memory_retrieval():
    """æµ‹è¯•è¯­ä¹‰è®°å¿†æ£€ç´¢ï¼ˆé€šè¿‡ V3 APIï¼‰"""
    print("\n" + "=" * 80)
    print("V3 API è¯­ä¹‰è®°å¿†æ£€ç´¢æµ‹è¯•ï¼ˆæ‰€æœ‰æ£€ç´¢æ¨¡å¼ï¼‰")
    print("=" * 80)
    
    repository = get_bean_by_type(ConversationMetaRawRepository)
    controller = AgenticV3Controller(repository)
    
    # æµ‹è¯•æŸ¥è¯¢
    test_query = "åŒ—äº¬æ—…æ¸¸"
    
    # æµ‹è¯•åœºæ™¯
    scenarios = [
        {
            "name": "user_001 - RRF èåˆ",
            "params": {
                "user_id": "user_001",
                "group_id": None,
                "retrieval_mode": "rrf",
            }
        },
        {
            "name": "user_001 - çº¯å‘é‡",
            "params": {
                "user_id": "user_001",
                "group_id": None,
                "retrieval_mode": "embedding",
            }
        },
        {
            "name": "user_001 - çº¯BM25",
            "params": {
                "user_id": "user_001",
                "group_id": None,
                "retrieval_mode": "bm25",
            }
        },
    ]
    
    print(f"\næŸ¥è¯¢: {test_query}")
    print(f"{'='*80}")
    
    for scenario in scenarios:
        print(f"\nğŸ“‹ åœºæ™¯: {scenario['name']}")
        print(f"   è¿‡æ»¤æ¡ä»¶: user_id={scenario['params']['user_id']}, "
              f"group_id={scenario['params']['group_id']}")
        print(f"   æ£€ç´¢æ¨¡å¼: {scenario['params']['retrieval_mode']}")
        
        request_data = {
            "query": test_query,
            "top_k": 5,
            "data_source": "semantic_memory",  # ä½¿ç”¨è¯­ä¹‰è®°å¿†æ•°æ®æº
            **scenario['params']
        }
        
        request = MockRequest(request_data)
        response = await controller.retrieve_lightweight(request)
        result = response.get("result", {})
        metadata = result.get("metadata", {})
        memories = result.get("memories", [])
        
        retrieval_mode = metadata.get("retrieval_mode", "N/A")
        latency = metadata.get("total_latency_ms", 0)
        embedding_candidates = metadata.get("embedding_candidates", 0)
        bm25_candidates = metadata.get("bm25_candidates", 0)
        
        print(f"   ç»“æœ: æ‰¾åˆ° {len(memories)} æ¡ (æ¨¡å¼: {retrieval_mode}, è€—æ—¶: {latency:.2f}ms)")
        if embedding_candidates > 0:
            print(f"        Embedding å€™é€‰: {embedding_candidates}")
        if bm25_candidates > 0:
            print(f"        BM25 å€™é€‰: {bm25_candidates}")
        
        if memories:
            for i, mem in enumerate(memories[:3], 1):
                score = mem.get('score', 0)
                episode = mem.get('episode', '')
                subject = mem.get('subject', '')
                display_text = subject if subject else episode[:40]
                timestamp = mem.get('timestamp', 'N/A')
                user_id = mem.get('user_id', 'N/A')
                memory_type = mem.get('memory_sub_type', 'N/A')
                
                # æ ¹æ®æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„åˆ†æ•°åç§°
                if retrieval_mode == "embedding":
                    score_label = "ä½™å¼¦ç›¸ä¼¼åº¦"
                elif retrieval_mode == "bm25":
                    score_label = "BM25åˆ†æ•°"
                else:
                    score_label = "RRFåˆ†æ•°"
                
                print(f"      [{i}] {score_label}={score:.4f} | {display_text}...")
                print(f"          æ—¶é—´: {timestamp} | user: {user_id} | type: {memory_type}")
        else:
            print(f"      âš ï¸  æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ç»“æœ")
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)
    print("\nâœ… è¯­ä¹‰è®°å¿†æ£€ç´¢å·²æˆåŠŸå°è£…åˆ° V3 API ä¸­ï¼")
    print("   æ”¯æŒä¸‰ç§æ£€ç´¢æ¨¡å¼ï¼š")
    print("   - embedding: çº¯å‘é‡æ£€ç´¢ï¼ˆé€šè¿‡ Milvusï¼‰")
    print("   - bm25: çº¯å…³é”®è¯æ£€ç´¢ï¼ˆé€šè¿‡ Elasticsearchï¼‰")
    print("   - rrf: RRF èåˆæ£€ç´¢ï¼ˆMilvus + ESï¼‰")
    print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
    print("""
    POST /api/v3/agentic/retrieve_lightweight
    {
      "query": "åŒ—äº¬æ—…æ¸¸",
      "user_id": "user_001",
      "top_k": 10,
      "data_source": "semantic_memory",
      "retrieval_mode": "rrf"  // æˆ– "embedding" æˆ– "bm25"
    }
    """)


if __name__ == "__main__":
    asyncio.run(test_semantic_memory_retrieval())

